# AI Provider Architecture

This directory contains the core logic for AI provider integration and prompt management.

## File Structure

```
provider/
├── __init__.py              # Package initialization
├── gemini_provider.py       # Gemini API wrapper
├── odoo_tools.py           # Smart tools for database operations
├── prompt_builder.py       # Dynamic prompt generation
└── README.md               # This file
```

## Components Overview

### 1. gemini_provider.py
**Purpose**: Wrapper around Google's Gemini API

- Simple, clean interface to Gemini
- Handles API authentication and requests
- Easy to extend for other providers (ChatGPT, Claude, etc.)

**Usage**:
```python
provider = GeminiProvider(api_key="your-key")
response = provider.generate_content(model="gemini-2.5-flash", contents="Hello")
```

---

### 2. odoo_tools.py
**Purpose**: Smart, reusable tools that Gemini can call to query the database

**Key Principle**: Tools must be GENERIC and DYNAMIC
- ✅ DO: Create tools that work with any model/field
- ❌ DON'T: Create tools with hardcoded models or specific queries

**Current Tools**:
- `search_records()`: Universal search tool for any Odoo model

**Example**:
```python
# Function declaration tells Gemini what the tool does
declaration = get_search_records_declaration()

# Function execution performs the actual database query
result = search_records(env, model='sale.order', count_only=True)
```

**Adding New Tools**:
1. Create a `get_TOOLNAME_declaration()` function that returns OpenAPI schema
2. Create a `TOOLNAME(env, ...)` function that executes the tool
3. Add to tool_declarations list in sh_ai_chat_message.py

---

### 3. prompt_builder.py
**Purpose**: Build dynamic, context-aware prompts for the AI

**Architecture**:
The complete prompt sent to Gemini consists of 4 parts:

#### System Prompt (User-Customizable)
- Stored in `sh.ai.llm.system_prompt` field
- Users can customize via LLM settings
- Defines base behavior and guidelines
- Example in: `data/demo_llm_provider.xml`

#### Dynamic Prompt 1: User & Company Context
Generated by: `build_user_company_context()`

Provides:
- Current user name, login, language
- Company name, currency, country
- Session info (date, timezone)

**Why**: So AI can personalize responses: "Hi John, you have $5000 in USD..."

#### Dynamic Prompt 2: Tools Documentation
Generated by: `build_tools_documentation(tool_declarations)`

Provides:
- List of all available tools
- Each tool's purpose and parameters
- Automatically includes new tools as you add them

**Why**: Gemini needs to know what tools it has access to and when to use them

#### Dynamic Prompt 3: Response Formatting Rules
Generated by: `build_response_formatting_rules()`

Provides:
- Markdown formatting guidelines
- Personalization rules (use user name, currency)
- Good/bad response examples
- Data presentation standards

**Why**: Ensures consistent, professional, well-formatted responses

**Usage**:
```python
from provider.prompt_builder import PromptBuilder

prompt_builder = PromptBuilder(env)
complete_prompt = prompt_builder.build_complete_prompt(
    system_prompt=llm.system_prompt,
    tool_declarations=[get_search_records_declaration()]
)
```

---

## How It All Works Together

```
User asks: "how many sale orders do I have?"
    ↓
[sh_ai_chat_message.py - process_user_message()]
    ↓
1. Build complete prompt:
   - System prompt (from LLM config)
   - + User/Company context (John @ ABC Corp, USD)
   - + Tools documentation (search_records tool available)
   - + Formatting rules (use markdown, show currency)
    ↓
2. Send to Gemini via gemini_provider.py:
   - User message + Complete prompt + Tool declarations
    ↓
3. Gemini analyzes and decides:
   - "I need to call search_records with model='sale.order', count_only=True"
    ↓
4. Execute tool (odoo_tools.py):
   - search_records(env, 'sale.order', count_only=True)
   - Returns: {"count": 20}
    ↓
5. Send result back to Gemini
    ↓
6. Gemini generates final response:
   - "Hi John, you have **20 sale orders**."
   - (Uses markdown, user name, proper formatting)
```

---

## Design Principles

### 1. Separation of Concerns
- **gemini_provider.py**: API communication only
- **odoo_tools.py**: Database operations only
- **prompt_builder.py**: Prompt generation only
- **Models**: Business logic orchestration

### 2. Scalability
- Easy to add new providers (ChatGPT, Claude)
- Easy to add new tools (just create declaration + function)
- Dynamic prompt generation scales with tools

### 3. Developer-Friendly
- Clear comments explaining "why" not just "what"
- Consistent naming conventions
- Self-documenting code structure

### 4. No Hardcoding
- No static model names in tools
- No hardcoded field lists
- Context-driven, dynamic behavior

---

## For New Developers

### To Add a New Tool:

1. **Create the tool in `odoo_tools.py`**:
```python
def get_my_new_tool_declaration():
    return {
        "name": "my_new_tool",
        "description": "What this tool does...",
        "parameters": {
            # OpenAPI schema
        }
    }

def my_new_tool(env, param1, param2):
    # Implementation
    return {"result": "..."}
```

2. **Register in `sh_ai_chat_message.py`**:
```python
tool_declarations = [
    get_search_records_declaration(),
    get_my_new_tool_declaration(),  # Add here
]
```

3. **Handle execution**:
```python
if function_call.name == "my_new_tool":
    result = my_new_tool(self.env, **dict(function_call.args))
```

That's it! The prompt builder will automatically document your new tool.

### To Add a New Provider (e.g., ChatGPT):

1. Create `chatgpt_provider.py` similar to `gemini_provider.py`
2. Implement the same interface: `generate_content(model, contents, config)`
3. Update `sh_ai_chat_message.py` to select provider based on `llm.sh_company`

---

## Questions?

If you're confused about any part of this architecture:
1. Read the inline comments in the code
2. Check the flow diagram above
3. Look at the examples in this README
4. Ask the team!

Remember: This architecture is designed to be simple, scalable, and easy to understand. If something seems overly complex, it probably needs refactoring.
